{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5. DBSCAN_Odev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "168  64.0  1.0  4.0     145.0  212.0  0.0      2.0    132.0    0.0      2.0   \n",
       "169  38.0  1.0  1.0     120.0  231.0  0.0      0.0    182.0    1.0      3.8   \n",
       "170  61.0  1.0  4.0     138.0  166.0  0.0      2.0    125.0    1.0      3.6   \n",
       "171  58.0  1.0  4.0     114.0  318.0  0.0      1.0    140.0    0.0      4.4   \n",
       "172  70.0  1.0  4.0     145.0  174.0  0.0      0.0    125.0    1.0      2.6   \n",
       "\n",
       "     slope   ca  thal       num  \n",
       "168    2.0  2.0   6.0  positive  \n",
       "169    2.0  0.0   7.0  positive  \n",
       "170    2.0  1.0   3.0  positive  \n",
       "171    3.0  3.0   6.0  positive  \n",
       "172    3.0  0.0   7.0  positive  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleveland = pd.read_excel('cleveland.xlsx')\n",
    "cleveland.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleveland['num'] = cleveland.num.replace({'positive':1, 'negative':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleveland = cleveland.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleveland.drop('num', axis=1)\n",
    "Y = cleveland.num\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Değişik eps ve min_samples değerleri deneyerek DBSCAN metodunu uygulayın. İki kümeli çözüm üretmenin pek kolay olmadığını göreceksiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. eps = 1, min_samples = 1, metric =\" euclidean \" şeklinde parametreleri ayarlayarak DBSCAN uygulayın. Ardından, min_samples değerini artırın. Artışın kümelerinin sayısı üzerindeki etkisi nedir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN çözümünün Düzeltilmiş Rand Endeksi (ARI): 0.00019672939276162575\n",
      "DBSCAN çözümünün siluet skoru: 0.041363030729666295\n"
     ]
    }
   ],
   "source": [
    "dbscan_cluster1 = DBSCAN(eps = 1, min_samples = 1)\n",
    "clusters_sample1 = dbscan_cluster1.fit_predict(X_std)\n",
    "\n",
    "print(\"DBSCAN çözümünün Düzeltilmiş Rand Endeksi (ARI): {}\"\n",
    "      .format(metrics.adjusted_rand_score(Y, clusters_sample1)))\n",
    "print(\"DBSCAN çözümünün siluet skoru: {}\"\n",
    "      .format(metrics.silhouette_score(X_std, clusters_sample1, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN çözümünün Düzeltilmiş Rand Endeksi (ARI): -0.07766445367108826\n",
      "DBSCAN çözümünün siluet skoru: -0.23625692396307046\n"
     ]
    }
   ],
   "source": [
    "dbscan_cluster2 = DBSCAN(eps = 1, min_samples = 2)\n",
    "clusters_sample2 = dbscan_cluster2.fit_predict(X_std)\n",
    "\n",
    "print(\"DBSCAN çözümünün Düzeltilmiş Rand Endeksi (ARI): {}\"\n",
    "      .format(metrics.adjusted_rand_score(Y, clusters_sample2)))\n",
    "print(\"DBSCAN çözümünün siluet skoru: {}\"\n",
    "      .format(metrics.silhouette_score(X_std, clusters_sample2, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN çözümünün Düzeltilmiş Rand Endeksi (ARI): -0.026395279412903618\n",
      "DBSCAN çözümünün siluet skoru: -0.1637567680101067\n"
     ]
    }
   ],
   "source": [
    "dbscan_cluster3 = DBSCAN(eps = 1, min_samples = 3)\n",
    "clusters_sample3 = dbscan_cluster3.fit_predict(X_std)\n",
    "\n",
    "print(\"DBSCAN çözümünün Düzeltilmiş Rand Endeksi (ARI): {}\"\n",
    "      .format(metrics.adjusted_rand_score(Y, clusters_sample3)))\n",
    "print(\"DBSCAN çözümünün siluet skoru: {}\"\n",
    "      .format(metrics.silhouette_score(X_std, clusters_sample3, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. eps = 1, min_samples = 1, metric =\" euclidean \" şeklinde parametreleri ayarlayarak DBSCAN uygulayın. Ardından, eps değerini artırın. Artışın kümelerinin sayısı üzerindeki etkisi nedir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN çözümünün Düzeltilmiş Rand Endeksi (ARI): 0.00019672939276162575\n",
      "DBSCAN çözümünün siluet skoru: 0.041363030729666295\n"
     ]
    }
   ],
   "source": [
    "dbscan_cluster1 = DBSCAN(eps = 1, min_samples = 1)\n",
    "clusters_eps1 = dbscan_cluster1.fit_predict(X_std)\n",
    "\n",
    "print(\"DBSCAN çözümünün Düzeltilmiş Rand Endeksi (ARI): {}\"\n",
    "      .format(metrics.adjusted_rand_score(Y, clusters_eps1)))\n",
    "print(\"DBSCAN çözümünün siluet skoru: {}\"\n",
    "      .format(metrics.silhouette_score(X_std, clusters_eps1, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN çözümünün Düzeltilmiş Rand Endeksi (ARI): 0.010501388890237379\n",
      "DBSCAN çözümünün siluet skoru: 0.07641365924351129\n"
     ]
    }
   ],
   "source": [
    "dbscan_cluster2 = DBSCAN(eps = 2, min_samples = 1)\n",
    "clusters_eps2 = dbscan_cluster2.fit_predict(X_std)\n",
    "\n",
    "print(\"DBSCAN çözümünün Düzeltilmiş Rand Endeksi (ARI): {}\"\n",
    "      .format(metrics.adjusted_rand_score(Y, clusters_eps2)))\n",
    "print(\"DBSCAN çözümünün siluet skoru: {}\"\n",
    "      .format(metrics.silhouette_score(X_std, clusters_eps2, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN çözümünün Düzeltilmiş Rand Endeksi (ARI): 0.1938527101239003\n",
      "DBSCAN çözümünün siluet skoru: -0.023966567686555005\n"
     ]
    }
   ],
   "source": [
    "dbscan_cluster3 = DBSCAN(eps = 3, min_samples = 1)\n",
    "clusters_eps3 = dbscan_cluster3.fit_predict(X_std)\n",
    "\n",
    "print(\"DBSCAN çözümünün Düzeltilmiş Rand Endeksi (ARI): {}\"\n",
    "      .format(metrics.adjusted_rand_score(Y, clusters_eps3)))\n",
    "print(\"DBSCAN çözümünün siluet skoru: {}\"\n",
    "      .format(metrics.silhouette_score(X_std, clusters_eps3, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
